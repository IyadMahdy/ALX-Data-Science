{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2665126",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Examples.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662d169",
   "metadata": {},
   "source": [
    "# Examples: Introduction to binary classification using logistic regression\n",
    "© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af890c",
   "metadata": {},
   "source": [
    "In this train, we'll delve into the fundamentals of classification, gaining insights into the theoretical underpinnings of logistic regression and its practical implementation using the `sklearn` library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d230d14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this train, you should be able to:\n",
    "- Understand the concept of binary classification. \n",
    "- Grasp the fundamentals of logistic regression. \n",
    "- Implement a logistic regression model using `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c3556d",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "\n",
    "### Quantitative vs. qualitative variables\n",
    "\n",
    "In this course we have explored a variety of ways which we can use to predict a response variable _Y_ when that response is quantitative, or numerical, in nature. The numerical variables we often predict typically exist on a continuous scale, and we can therefore fit things like a linear regression which, for increasing values of X, there's appropriate increasing/decreasing values of Y. An example of linear regression is shown below.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/sketch-linear-reg.png\" alt=\"sketch-linear-reg\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789f4bcb",
   "metadata": {},
   "source": [
    "In some cases, however, the response variable Y in our dataset will not be continuous - it will be categorical(qualitative). The prediction task in this case is known as _classification,_ because we are trying to _classify_ into which category an observation belongs.\n",
    "\n",
    "The simplest version of this scenario is known as _binary classification_. Binary refers to the fact that there are two categories. It is normally intuitive to encode the two classes in a binary classification task as zeroes and ones.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/sketch-categorical-y.png\" alt=\"sketch-categorical-y\" style=\"width: 300px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736021e7",
   "metadata": {},
   "source": [
    "With our response variable encoded as zeroes and ones, we are able to plot some of the data points for a predictor variable X, and see the peculiar problem we are faced with: the response values lie along two distinct horizontal lines. What's more, they only ever take on values of 0 and 1! Clearly no good for a linear regression, which is only ever monotonically increasing or decreasing.\n",
    "\n",
    "Looking at the values for Y which lie along an example linear regression line, we can see that for very large X, we will be getting values for Y which are greater than 1, and as X decreases, we may even get negative Y values - far from the zeroes and ones we need.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/sketch-linear-classification.png\" alt=\"sketch-linear-classification\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4951e081",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b981bfe1",
   "metadata": {},
   "source": [
    "The solution to this problem is known as *logistic regression*, so-called because it makes use of a common S-shaped curve known as the logistic function. This curve is commonly known as a _sigmoid_. It solves the problem for the following reasons:\n",
    "\n",
    "- It squeezes the range of output values to exist only between 0 and 1.\n",
    "- It has a point of inflection, which can be used to separate the feature space into two distinct areas (one for each class).\n",
    "- It has shallow gradients at both its top and bottom, which can be mapped to zeroes or ones respectively with little ambiguity.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/sketch-logistic-regression.png\" alt=\"sketch-logistic-regression\" style=\"width: 600px;\"/>\n",
    "\n",
    "The name is a little confusing because it contains the word _regression_. That's because we are effectively doing a linear regression, but then squeezing that linear regression vertically down into the S-shape sigmoid curve, so that it exists between 0 and 1. Rest assured - this is definitely a **classification model**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257f5f8d",
   "metadata": {},
   "source": [
    "The logistic regression model produces output values for the response variable which again lie on the curve itself. However, unlike regression, where the output value was also the prediction value, in logistic regression the output value is a _probability_. The value along the curve (which, remember, is always between zero and one), is equal to the probability of the observation belonging to class 1 in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85597a13",
   "metadata": {},
   "source": [
    "### The Logistic Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f8eb1b",
   "metadata": {},
   "source": [
    "We now know that the output value of a logistic regression model refers to the probability that the observation in question belongs to class 1. The output values all fall between 0 and 1, which is all very well. But at what threshold value do we decide that a probability is too low to be assigned to class 1? Usually, we pick 0.5. That is:\n",
    "\n",
    "- Values greater than or equal to 0.5 are assigned to class 1; and\n",
    "- Values less than 0.5 are assigned to class 0.\n",
    "\n",
    "This output needs to hold for all values of X. In other words, regardless of the value of X, we need the output to be a value between 0 and 1. The function that takes care of all this is defined as follows:\n",
    "\n",
    "$$P(X) = \\displaystyle \\frac{e^{\\beta_0 + \\beta_1 X}}{1+e^{\\beta_0 + \\beta_1 X}}$$\n",
    "\n",
    "where $P(X)$ is the probability of X belonging to class 1, and $\\beta_0$ and $\\beta_1$ are the intercept and regression coefficient respectively, just like in a linear regression model. After a bit of manipulation we arrive at:\n",
    "\n",
    "\\begin{align}\n",
    "1 - P(X) &= \\displaystyle \\frac{1}{1+e^{\\beta_0 + \\beta_1 X}} \\\\\n",
    "\\therefore \\log \\left( \\frac{P(X)}{1-P(X)} \\right) &= {\\beta_0 + \\beta_1 X}\n",
    "\\end{align}\n",
    "\n",
    "The term on the left is known as the **log odds ratio**. Without the log sign in front of it, it is known simply as the odds ratio. While $P(X)$ is bounded between 0 and 1, the odds ratio is bounded between 0 and $\\infty$. \n",
    "\n",
    "_Note: if you're still having trouble understanding the concept of log odds ratios, please checkout videos in the additional links section._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c588cf",
   "metadata": {},
   "source": [
    "### Multi-Class Classification\n",
    "\n",
    "There will clearly be cases when we have more than two categories in our labels column. Perhaps we are classifying the colour of cars into one of: `[red, green, blue]`.\n",
    "\n",
    "As we have seen, the logistic regression algorithm is effective for those situations with no more than two classes. There is, however, a neat way to combine logistic regression models for multi-class classification in what is known as the one-vs-rest approach (or OvR).\n",
    "\n",
    "In the OvR case, a separate logistic regression model is trained for each label that the response variable takes on. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/sketch-one-vs-rest.png\" alt=\"sketch-one-vs-rest\" style=\"width: 600px;\"/>\n",
    "\n",
    "Fortunately, `sklearn` makes it very simple to implement this multi-class extension of the logistic regression algorithm. We'll include a note on it in this train and the actual code for it later on in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65a1938",
   "metadata": {},
   "source": [
    "### Non-Linearly Separable Data Points\n",
    "\n",
    "One last thing to note here before we move onto implementation. Logistic regression models are effective only for those cases in which we have clearly linearly separable data. That is to say, a straight line or hyperplane can be placed somewhere amongst the datapoints that definitively separates them.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/sketch-non-separable.png\" alt=\"sketch-non-separable\" style=\"width: 600px;\"/>\n",
    "\n",
    "In those cases that our data is not linearly separable, we will need to try out other algorithms (perhaps linear discriminant analysis, or a support vector classifier). Later on in the course, we will explore many more models to carry out more complex classification tasks. Stay tuned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5072e9a1",
   "metadata": {},
   "source": [
    "## Building a Logistic Regression Model\n",
    "\n",
    "In this train we will build a classification model to predict whether the policholder of some insurance product will claim from their insurance within the upcoming year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05466626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4578841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>steps</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>insurance_claim</th>\n",
       "      <th>claim_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>3009</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>yes</td>\n",
       "      <td>16884.9240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>3008</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>yes</td>\n",
       "      <td>1725.5523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3009</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>10009</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>8010</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>yes</td>\n",
       "      <td>3866.8552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  steps  children smoker     region insurance_claim  \\\n",
       "0   19  female  27.900   3009         0    yes  southwest             yes   \n",
       "1   18    male  33.770   3008         1     no  southeast             yes   \n",
       "2   28    male  33.000   3009         3     no  southeast              no   \n",
       "3   33    male  22.705  10009         0     no  northwest              no   \n",
       "4   32    male  28.880   8010         0     no  northwest             yes   \n",
       "\n",
       "   claim_amount  \n",
       "0    16884.9240  \n",
       "1     1725.5523  \n",
       "2        0.0000  \n",
       "3        0.0000  \n",
       "4     3866.8552  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data in and view first few entries\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/classification_sprint/claims_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b775f025",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17397563",
   "metadata": {},
   "source": [
    "We will start by preparing the data to be used in the logistic regression algorithm, this involves:\n",
    "\n",
    "- Splitting the data into features and labels;\n",
    "- Transforming the categorical features (create dummy variables);\n",
    "- Splitting the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ceb72d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "y = df['insurance_claim']\n",
    "\n",
    "# features\n",
    "X = df.drop('insurance_claim', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5af33aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>steps</th>\n",
       "      <th>children</th>\n",
       "      <th>claim_amount</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>3009</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.9240</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>3008</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.5523</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3009</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>10009</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>8010</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.8552</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>30.970</td>\n",
       "      <td>4008</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>31.920</td>\n",
       "      <td>3003</td>\n",
       "      <td>0</td>\n",
       "      <td>2205.9808</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>36.850</td>\n",
       "      <td>3008</td>\n",
       "      <td>0</td>\n",
       "      <td>1629.8335</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>25.800</td>\n",
       "      <td>8009</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>29.070</td>\n",
       "      <td>8008</td>\n",
       "      <td>0</td>\n",
       "      <td>29141.3603</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  steps  children  claim_amount  sex_male  smoker_yes  \\\n",
       "0      19  27.900   3009         0    16884.9240     False        True   \n",
       "1      18  33.770   3008         1     1725.5523      True       False   \n",
       "2      28  33.000   3009         3        0.0000      True       False   \n",
       "3      33  22.705  10009         0        0.0000      True       False   \n",
       "4      32  28.880   8010         0     3866.8552      True       False   \n",
       "...   ...     ...    ...       ...           ...       ...         ...   \n",
       "1333   50  30.970   4008         3        0.0000      True       False   \n",
       "1334   18  31.920   3003         0     2205.9808     False       False   \n",
       "1335   18  36.850   3008         0     1629.8335     False       False   \n",
       "1336   21  25.800   8009         0        0.0000     False       False   \n",
       "1337   61  29.070   8008         0    29141.3603     False        True   \n",
       "\n",
       "      region_northwest  region_southeast  region_southwest  \n",
       "0                False             False              True  \n",
       "1                False              True             False  \n",
       "2                False              True             False  \n",
       "3                 True             False             False  \n",
       "4                 True             False             False  \n",
       "...                ...               ...               ...  \n",
       "1333              True             False             False  \n",
       "1334             False             False             False  \n",
       "1335             False              True             False  \n",
       "1336             False             False              True  \n",
       "1337              True             False             False  \n",
       "\n",
       "[1338 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming the Features\n",
    "X_transformed = pd.get_dummies(X, drop_first=True)\n",
    "X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16a60d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ce513ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac3e4b4",
   "metadata": {},
   "source": [
    "Our data is now ready. Let's train the logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b026cd",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033127ae",
   "metadata": {},
   "source": [
    "We need the LogisticRegression module from `sklearn.linear_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274a665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e94a93",
   "metadata": {},
   "source": [
    "We create an instance of the `LogisticRegression()` object using the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "577376d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92431d2d",
   "metadata": {},
   "source": [
    "We use the `fit()` method to train the model.\n",
    "\n",
    "**Pro-tip**: in the multi-class case we referred to above, the `LogisticRegression` instance takes a simple argument which enables it to be used for 2+ classes: `multi_class='ovr'`. We'll revisit this later in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2a46296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4458b2",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can extract the parameters. The parameters consist of the intercept and the coefficients related to the features. These parameters can be used to predict future claims given the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a5a8fc",
   "metadata": {},
   "source": [
    "#### Intercept\n",
    "\n",
    "The interpretation of the parameters of the logistic model is not quite the same as for a linear regression model. \n",
    "\n",
    "In binary classification, the class with value 1 is known as the _reference class_. Let's explore.\n",
    "\n",
    "The intercept, $\\beta_0$, is interpreted as the **log odds** ratio of an observation being in the reference class when all other predictor variables are equal to zero.\n",
    "\n",
    "We can exponentiate this value, in other words raise the natural number $e$ to this value, to convert it to a typical **odds** ratio. In other words:\n",
    "\n",
    "$$Odds = e^{\\beta_0}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "048bbc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.769813303061967e-05"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f3aa2d",
   "metadata": {},
   "source": [
    "#### Coefficients\n",
    "\n",
    "For binary categorical variables, like `smoker` and `sex`, the coefficient is interpreted as the **log odds** ratio between the class implied by a zero for the variable (i.e. non-smoker), and the class implied by a one for the variable (i.e. smoker).\n",
    "\n",
    "For continuous variables, the coefficient is interpreted as the expected change in the log odds for a one-unit increase in the variable.\n",
    "\n",
    "Again, we can arrive at the usual odds value by exponentiating the coefficient:\n",
    "\n",
    "$$Odds = e^{\\beta_1}$$\n",
    "\n",
    "Effectively, each coefficient is a measure of the change in the log odds of belonging to the reference class for one-unit changes in the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ed43c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.002559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>-0.001818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>steps</th>\n",
       "      <td>-0.004556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>-0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claim_amount</th>\n",
       "      <td>0.038042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_male</th>\n",
       "      <td>-0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker_yes</th>\n",
       "      <td>-0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_northwest</th>\n",
       "      <td>-0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_southeast</th>\n",
       "      <td>-0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_southwest</th>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Coefficient\n",
       "age                 -0.002559\n",
       "bmi                 -0.001818\n",
       "steps               -0.004556\n",
       "children            -0.000208\n",
       "claim_amount         0.038042\n",
       "sex_male            -0.000007\n",
       "smoker_yes          -0.000013\n",
       "region_northwest    -0.000023\n",
       "region_southeast    -0.000014\n",
       "region_southwest     0.000005"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_df = pd.DataFrame(lr.coef_.T, X_transformed.columns, columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1072929",
   "metadata": {},
   "source": [
    "In your own time: What can you infer from the coefficients above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8599a093",
   "metadata": {},
   "source": [
    "### Prediction Time\n",
    "\n",
    "Next we will use the `predict` method to obtain predictions from our test data observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37b9028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9efc8d",
   "metadata": {},
   "source": [
    "Now that we have some predictions from our model, we are in a position to assess the performance of the model. In regression, we were concerned with _error rate_ , or the average closeness of our predictions to the ground truth values.\n",
    "\n",
    "In classification, we are concerned with _accuracy_ , or more broadly, how many of the observations did we correctly assign to the two classes, zero and one.\n",
    "\n",
    "The metrics and methods used to measure classification accuracy are extensive, and we'll dive into them in an upcoming train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce6d514",
   "metadata": {},
   "source": [
    "## Advantages & Disadvantages of Logistic Regression\n",
    "\n",
    "**Advantages**\n",
    "\n",
    "- Convenient probability scores for observations (probability of each outcome is transformed into a classification);\n",
    "- Not a major issue if there is collinearity among features (much worse with linear regression).\n",
    "\n",
    "**Disadvantages**\n",
    "\n",
    "- Can overfit when data is unbalanced (i.e.: we have far more observations in one class than the other);\n",
    "- Doesn't handle large number of categorical variables well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb08bfa",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this train we have seen or been introduced to:\n",
    "- Classification, and specifically binary (or two-class) classification;\n",
    "- Logistic regression, its similarities and differences compared to linear regression;\n",
    "- As well its effectiveness and simplicity in binary classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd094b-0fee-46f1-a4b8-73766813c42b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
